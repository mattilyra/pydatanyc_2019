{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformer and BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Vaswani et al., [Attention is All you Need.](https://papers.nips.cc/paper/7181-attention-is-all-you-need) NIPS 2017: 5998-6008\n",
    "- Devlin et al., [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.](https://www.aclweb.org/anthology/N19-1423/) NAACL-HLT (1) 2019: 4171-4186\n",
    "\n",
    "---\n",
    "\n",
    "- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "- [The Illustrated BERT, ELMo ...](https://jalammar.github.io/illustrated-bert/)\n",
    "- [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1996, 2047, 4068, 3199, 1006, 2022, 2099, 1007, 2097, 2330, 2574, 1012]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer.encode('The new Berlin airport (BER) will open soon.')\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'new',\n",
       " 'berlin',\n",
       " 'airport',\n",
       " '(',\n",
       " 'be',\n",
       " '##r',\n",
       " ')',\n",
       " 'will',\n",
       " 'open',\n",
       " 'soon',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_train = fetch_20newsgroups(data_home='./data', subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "news_test = fetch_20newsgroups(data_home='./data', subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.',\n",
       " \"A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train.target[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.autos',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.graphics',\n",
       " 'sci.space',\n",
       " 'talk.politics.guns',\n",
       " 'sci.med',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.mac.hardware']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[news_train.target_names[l] for l in news_train.target[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "label_map = {}\n",
    "\n",
    "def map_label(label_idx):\n",
    "    \"\"\"Collapse 20newsgroups labels to just the top level in the hierarchy.\"\"\"\n",
    "    label_name = news_train.target_names[label_idx]\n",
    "    top_level, *_ = label_name.partition('.')\n",
    "    label_idx_ = label_map.get(top_level, len(label_map))\n",
    "    if label_idx_ == len(label_map):\n",
    "        label_map[top_level] = len(label_map)\n",
    "    return label_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "def doc2bert(doc, tokenizer):\n",
    "    tokens = tokenizer.tokenize(doc)[:510]  # NOTE: that's 510 SUBword tokens, not 510 tokens from the original document\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    # pad everything to 512\n",
    "    if len(token_ids) < 510:\n",
    "        token_ids = token_ids + [0] * (510 - len(token_ids))\n",
    "        \n",
    "    return [tokenizer.cls_token_id] + token_ids + [tokenizer.sep_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "token_ids = (doc2bert(x_, tokenizer) for x_ in news_train.data)\n",
    "labels = (map_label(y_idx) for y_idx in data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "\n",
    "X_train = torch.LongTensor(list(token_ids))\n",
    "y_train = torch.LongTensor(list(labels))\n",
    "\n",
    "batch_size = 8\n",
    "data_train = TensorDataset(X_train, y_train)\n",
    "sampler = RandomSampler(data_train)\n",
    "train_dataloader = DataLoader(data_train, sampler=sampler, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(torch.unique(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have quick look at what the output from looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3807,  0.1909,  0.0166, -0.5077,  0.0076, -0.6273,  0.3293],\n",
       "        [-0.3634,  0.1780,  0.0267, -0.5110,  0.0051, -0.5655,  0.2807],\n",
       "        [-0.3536,  0.0814, -0.2408, -0.4647, -0.0209, -0.5122,  0.3360],\n",
       "        [-0.4025,  0.1827, -0.0040, -0.4701,  0.0337, -0.6225,  0.3736]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, *_ = bert(X_train[:4])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1060, 0.1878, 0.1578, 0.0934, 0.1564, 0.0829, 0.2157],\n",
       "        [0.1084, 0.1863, 0.1601, 0.0935, 0.1567, 0.0886, 0.2064],\n",
       "        [0.1136, 0.1756, 0.1272, 0.1017, 0.1585, 0.0970, 0.2265],\n",
       "        [0.1027, 0.1843, 0.1529, 0.0959, 0.1588, 0.0824, 0.2231]],\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.log_softmax(output, dim=1).exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import WarmupLinearSchedule\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "# pass the parameters of the classifier head ONLY to the optimizer\n",
    "params = [p for n, p in bert.named_parameters() if 'classifier.' in n]\n",
    "optimizer = AdamW(params, lr=3e-5, correct_bias=False)\n",
    "\n",
    "num_total_steps = num_epochs * (len(train_dataloader.sampler) // batch_size)\n",
    "num_warmup_steps = int(num_total_steps * 0.15)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Schedule\n",
    "## Warmup Linear Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_learning_rate(num_warmup_steps):\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)\n",
    "    learning_rates = []\n",
    "    for i in range(num_total_steps):\n",
    "        learning_rates.append(scheduler.get_lr())\n",
    "        scheduler.step()\n",
    "    plt.plot(learning_rates);\n",
    "    plt.xlabel('Iteration');\n",
    "    plt.ylabel('Learning Rate');\n",
    "\n",
    "plot_learning_rate(int(num_total_steps * 0.05))\n",
    "plot_learning_rate(int(num_total_steps * 0.10))\n",
    "plot_learning_rate(int(num_total_steps * 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification with BERT (20 newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1670acd71a41e0904df0a63865b871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8285715f6a5946359184c6eddf70a262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e480eb0fb94e908757d4a7361ee816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f603617f41af4a428abb134f9b16c9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1df7816cf24e589db98bb262d377b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1feb2a5b054328a778f31e6c0d85fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdmn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# Use a GPU if one is available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert.to(DEVICE)\n",
    "\n",
    "for _ in tqdmn(range(num_epochs), total=num_epochs, desc=\"Epoch\"):\n",
    "    steps = tqdmn(train_dataloader,\n",
    "                  total=X_train.size()[0] // train_dataloader.batch_size + 1,\n",
    "                  desc='Mini-batch')\n",
    "    train_loss = 0\n",
    "    for i_step, batch in enumerate(steps):\n",
    "        batch_X, batch_y = (b.to(DEVICE) for b in batch)\n",
    "        loss, *_ = bert(batch_X, labels=batch_y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(bert.parameters(), 1.0)\n",
    "        steps.set_postfix_str(f'avg. loss {train_loss / (i_step + 1):.4f}')\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bert.to('cpu')\n",
    "torch.save(bert.to('cpu'), 'bert-20news-5epochs-HEAD.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "X_test, y_test = zip(*[([tokenizer.cls_token_id] + tokenize(x, tokenizer) + [tokenizer.sep_token_id],\n",
    "                         map_label(y_idx))\n",
    "                        for x, y_idx in zip(data_test['data'], data_test['target'])])\n",
    "label_map = {label: idx for idx, label in enumerate(set(y_test))}\n",
    "y_test = [label_map[y_] for y_ in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "X_test = torch.LongTensor(X_test)\n",
    "\n",
    "batch_size = 4\n",
    "data_test = TensorDataset(X_test)\n",
    "sampler = SequentialSampler(data_test)\n",
    "test_dataloader = DataLoader(data_test, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "bert.eval()\n",
    "bert.to(DEVICE)\n",
    "pred = []\n",
    "for x, *_batch in test_dataloader:\n",
    "    x = x.to(DEVICE)\n",
    "    pred_, *_ = bert(x)\n",
    "    _, pred_ = F.log_softmax(pred_, dim=1).exp().max(dim=1)\n",
    "    pred.extend(pred_.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         soc       0.00      0.00      0.00       398\n",
      "         rec       0.00      0.00      0.00      1590\n",
      "         alt       0.05      0.08      0.06       319\n",
      "         sci       0.00      0.00      0.00      1579\n",
      "        misc       0.00      0.00      0.00       390\n",
      "        talk       0.30      0.18      0.22      1301\n",
      "        comp       0.27      0.87      0.42      1955\n",
      "\n",
      "    accuracy                           0.26      7532\n",
      "   macro avg       0.09      0.16      0.10      7532\n",
      "weighted avg       0.12      0.26      0.15      7532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/pydatanyc_2019-QOOn-cei/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, pred, target_names=list(label_map.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Linear SVM with parameter tuning\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "            comp       0.84      0.87      0.86      1955\n",
    "             soc       0.73      0.71      0.72       398\n",
    "            talk       0.74      0.77      0.75      1301\n",
    "             sci       0.78      0.73      0.76      1579\n",
    "            misc       0.82      0.76      0.79       390\n",
    "             rec       0.79      0.86      0.83      1590\n",
    "             alt       0.62      0.41      0.49       319\n",
    "\n",
    "        accuracy                           0.79      7532\n",
    "       macro avg       0.76      0.73      0.74      7532\n",
    "    weighted avg       0.79      0.79      0.79      7532\n",
    "    \n",
    "---\n",
    "\n",
    "      BERT with fine-tuning the whole transformer stack\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "             soc       0.55      0.70      0.61       398\n",
    "             rec       0.82      0.69      0.75      1590\n",
    "             alt       0.02      0.08      0.03       319\n",
    "             sci       0.21      0.09      0.12      1579\n",
    "            misc       0.81      0.55      0.65       390\n",
    "            talk       0.63      0.58      0.60      1301\n",
    "            comp       0.79      0.85      0.82      1955\n",
    "\n",
    "        accuracy                           0.55      7532\n",
    "       macro avg       0.54      0.51      0.51      7532\n",
    "    weighted avg       0.60      0.55      0.57      7532\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dce8f4eb0e5480f96cd175c8b5e8dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea231822127b4f6197d68dd4786d78dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6597f5d45812427e83ddd335dfa756d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d050185b4b4077b36274063ae3ed37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c0fcb81a1341c384d5ffda695a4111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbda6f2345249a7bcc153e0294a8099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from transformers.optimization import WarmupLinearSchedule\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdmn\n",
    "\n",
    "num_epochs = 5\n",
    "bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(torch.unique(y_train)))\n",
    "params = [p for n, p in bert.named_parameters()]  # if .classifier in n]\n",
    "optimizer = AdamW(params, lr=3e-5, correct_bias=False)\n",
    "\n",
    "num_total_steps = num_epochs * (len(train_dataloader.sampler)\n",
    "                              // batch_size)\n",
    "num_warmup_steps = int(num_total_steps * 0.15)\n",
    "scheduler = WarmupLinearSchedule(optimizer,\n",
    "                                 warmup_steps=num_warmup_steps,\n",
    "                                 t_total=num_total_steps)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert.to(DEVICE)\n",
    "\n",
    "for _ in tqdmn(range(num_epochs), total=num_epochs, desc=\"Epoch\"):\n",
    "    steps = tqdmn(train_dataloader,\n",
    "                  total=X_train.size()[0] // train_dataloader.batch_size + 1,\n",
    "                  desc='Mini-batch')\n",
    "    train_loss = 0\n",
    "    for i_step, batch in enumerate(steps):\n",
    "        batch_X, batch_y = (b.to(DEVICE) for b in batch)\n",
    "        loss, *_ = bert(batch_X, labels=batch_y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(bert.parameters(), 1.0)\n",
    "        steps.set_postfix_str(f'avg. loss {train_loss / (i_step + 1):.4f}')\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bert.to('cpu')\n",
    "torch.save(bert.to('cpu'), 'bert-20news-5epochs-ALL.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "X_test = torch.LongTensor(X_test)\n",
    "\n",
    "batch_size = 4\n",
    "data_test = TensorDataset(X_test)\n",
    "sampler = SequentialSampler(data_test)\n",
    "test_dataloader = DataLoader(data_test, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "bert.eval()\n",
    "bert.to(DEVICE)\n",
    "pred = []\n",
    "for x, *_batch in test_dataloader:\n",
    "    x = x.to(DEVICE)\n",
    "    pred_, *_ = bert(x)\n",
    "    _, pred_ = F.log_softmax(pred_, dim=1).exp().max(dim=1)\n",
    "    pred.extend(pred_.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         soc       0.55      0.70      0.61       398\n",
      "         rec       0.82      0.69      0.75      1590\n",
      "         alt       0.02      0.08      0.03       319\n",
      "         sci       0.21      0.09      0.12      1579\n",
      "        misc       0.81      0.55      0.65       390\n",
      "        talk       0.63      0.58      0.60      1301\n",
      "        comp       0.79      0.85      0.82      1955\n",
      "\n",
      "    accuracy                           0.55      7532\n",
      "   macro avg       0.54      0.51      0.51      7532\n",
      "weighted avg       0.60      0.55      0.57      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, pred, target_names=list(label_map.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "# License: BSD 3 clause\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(tol=1e-3)),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    # 'tfidf__use_idf': (True, False),\n",
    "    # 'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__max_iter': (20,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 120 out of 120 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1630.918s\n",
      "\n",
      "Best score: 0.827\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__max_iter: 20\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "def map_label(label_idx):\n",
    "    return data['target_names'][label_idx].split('.')[0]\n",
    "\n",
    "y_names = list(map(map_label, data.target))\n",
    "label_map = {label: idx for idx, label in enumerate(set(y_names))}\n",
    "y = [label_map[y_] for y_ in y_names]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "grid_search.fit(data.data, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "data_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "y_test = [label_map[map_label(y_)] for y_ in data_test.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        comp       0.84      0.87      0.86      1955\n",
      "         soc       0.73      0.71      0.72       398\n",
      "        talk       0.74      0.77      0.75      1301\n",
      "         sci       0.78      0.73      0.76      1579\n",
      "        misc       0.82      0.76      0.79       390\n",
      "         rec       0.79      0.86      0.83      1590\n",
      "         alt       0.62      0.41      0.49       319\n",
      "\n",
      "    accuracy                           0.79      7532\n",
      "   macro avg       0.76      0.73      0.74      7532\n",
      "weighted avg       0.79      0.79      0.79      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,\n",
    "                                    grid_search.best_estimator_.predict(data_test.data),\n",
    "                                    target_names=list(label_map.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German News Categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_gnad\n",
    "\n",
    "gnad_train, gnad_test = load_gnad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sport</td>\n",
       "      <td>21-Jhriger fllt wohl bis Saisonende aus. Wie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Kultur</td>\n",
       "      <td>'Erfundene Bilder zu Filmen, die als verloren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Web</td>\n",
       "      <td>Der frischgekrte CEO Sundar Pichai setzt auf ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>Putin: \"Einigung, dass wir Menge auf Niveau vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Inland</td>\n",
       "      <td>Estland sieht den knftigen sterreichischen P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               text\n",
       "0       Sport  21-Jhriger fllt wohl bis Saisonende aus. Wie...\n",
       "1      Kultur  'Erfundene Bilder zu Filmen, die als verloren ...\n",
       "2         Web  Der frischgekrte CEO Sundar Pichai setzt auf ...\n",
       "3  Wirtschaft  Putin: \"Einigung, dass wir Menge auf Niveau vo...\n",
       "4      Inland  Estland sieht den knftigen sterreichischen P..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnad_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=3)]: Done 120 out of 120 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        tok...\n",
       "                                                      shuffle=True, tol=0.001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=3,\n",
       "             param_grid={'clf__alpha': (1e-05, 1e-06), 'clf__max_iter': (20,),\n",
       "                         'clf__penalty': ('l2', 'elasticnet'),\n",
       "                         'vect__max_df': (0.5, 0.75, 1.0),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(gnad_train.category)\n",
    "grid_search.fit(gnad_train.text, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if BERT can do better than that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Etat       0.94      0.76      0.84        67\n",
      "       Inland       0.81      0.84      0.83       102\n",
      "International       0.89      0.83      0.86       151\n",
      "       Kultur       0.91      0.89      0.90        54\n",
      "     Panorama       0.81      0.84      0.82       168\n",
      "        Sport       0.99      0.98      0.99       120\n",
      "          Web       0.92      0.91      0.91       168\n",
      "   Wirtschaft       0.82      0.87      0.85       141\n",
      " Wissenschaft       0.87      0.96      0.92        57\n",
      "\n",
      "     accuracy                           0.88      1028\n",
      "    macro avg       0.88      0.88      0.88      1028\n",
      " weighted avg       0.88      0.88      0.88      1028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_test = label_encoder.transform(gnad_test.category)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test,\n",
    "                                    grid_search.best_estimator_.predict(gnad_test.text),\n",
    "                                    target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "token_ids = (doc2bert(x_, tokenizer) for x_ in gnad_train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "\n",
    "X_train = torch.LongTensor(list(token_ids))\n",
    "y_train = torch.LongTensor(y)\n",
    "\n",
    "batch_size = 8\n",
    "data_train = TensorDataset(X_train, y_train)\n",
    "sampler = RandomSampler(data_train)\n",
    "train_dataloader = DataLoader(data_train, sampler=sampler, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from transformers.optimization import WarmupLinearSchedule\n",
    "\n",
    "num_epochs = 5\n",
    "bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=len(torch.unique(y_train)))\n",
    "params = [p for n, p in bert.named_parameters()]\n",
    "optimizer = AdamW(params, lr=3e-5, correct_bias=False)\n",
    "\n",
    "\n",
    "num_total_steps = num_epochs * (len(train_dataloader.sampler) // batch_size)\n",
    "num_warmup_steps = int(num_total_steps * 0.15)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1670acd71a41e0904df0a63865b871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8285715f6a5946359184c6eddf70a262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e480eb0fb94e908757d4a7361ee816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f603617f41af4a428abb134f9b16c9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1df7816cf24e589db98bb262d377b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1feb2a5b054328a778f31e6c0d85fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Mini-batch', max=1415, style=ProgressStyle(description_width="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdmn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# Use a GPU if one is available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert.to(DEVICE)\n",
    "\n",
    "for _ in tqdmn(range(num_epochs), total=num_epochs, desc=\"Epoch\"):\n",
    "    steps = tqdmn(train_dataloader,\n",
    "                  total=X_train.size()[0] // train_dataloader.batch_size + 1,\n",
    "                  desc='Mini-batch')\n",
    "    train_loss = 0\n",
    "    for i_step, batch in enumerate(steps):\n",
    "        batch_X, batch_y = (b.to(DEVICE) for b in batch)\n",
    "        loss, *_ = bert(batch_X, labels=batch_y)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(bert.parameters(), 1.0)\n",
    "        steps.set_postfix_str(f'avg. loss {train_loss / (i_step + 1):.4f}')\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "rise": {
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
